{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "adjust_feature_lgb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr7uekADom4t"
      },
      "source": [
        "### **初始化准备基本运行环境**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmwEy7ZkNER2"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoNzPwqBUxEM"
      },
      "source": [
        "pd.set_option('display.max_columns', None)\r\n",
        "pd.set_option('display.max_rows', None)\r\n",
        "np.set_printoptions(suppress=True)\r\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvj4Ia9QU9e4"
      },
      "source": [
        "from sklearn.model_selection import KFold\r\n",
        "import lightgbm as lgb\r\n",
        "from sklearn import metrics"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV_Ty8REdLx9",
        "outputId": "d182c81f-4cfa-4688-cfad-b5fef672b841"
      },
      "source": [
        "!ls drive/MyDrive/TestDataSet/final/"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_final.csv\ttrain_final.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-lhEPw3VBJ8"
      },
      "source": [
        "train = pd.read_csv('drive/MyDrive/TestDataSet/final/train_final.csv')\r\n",
        "test = pd.read_csv('drive/MyDrive/TestDataSet/final/test_final.csv')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POzMHk6IhlOh"
      },
      "source": [
        "def getLabel(x):\r\n",
        "    threshold = 0.5\r\n",
        "    z = np.where(x>=threshold,1,0)\r\n",
        "    return z"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ_93PbDk7-n"
      },
      "source": [
        "## **baseline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mP0-BBehm_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "040fcc66-07fe-45c9-b63e-f55de893357b"
      },
      "source": [
        "#baseline\r\n",
        "train_copy = train.copy()\r\n",
        "folds = KFold(n_splits=5,shuffle=True, random_state=42)\r\n",
        "loss_train_list = []\r\n",
        "loss_eval_list = []\r\n",
        "loss_test_list = []\r\n",
        "\r\n",
        "\r\n",
        "for train_ix, eval_ix in folds.split(train_copy):\r\n",
        "    train_df = train_copy.loc[train_ix]\r\n",
        "    eval_df = train_copy.loc[eval_ix]\r\n",
        "    \r\n",
        "    clf = lgb.LGBMClassifier(boosting_type='gbdt', \r\n",
        "      objective =\"binary\",\r\n",
        "      metric= 'binary_logloss',\r\n",
        "      ).fit(train_df.drop(columns=['loan_status']), train_df['loan_status'],\r\n",
        "            eval_names=[\"train\",\"val\"],\r\n",
        "            eval_set=[(train_df.drop(columns=['loan_status']), train_df['loan_status']),\r\n",
        "                      (eval_df.drop(columns=['loan_status']), eval_df['loan_status'])],\r\n",
        "            eval_metric='binary_logloss',\r\n",
        "            verbose=20)\r\n",
        "    \r\n",
        "    ytrain = clf.predict_proba(train_df.drop(columns=['loan_status']))[:,1]\r\n",
        "    yeval = clf.predict_proba(eval_df.drop(columns=['loan_status']))[:,1]\r\n",
        "    ytest = clf.predict_proba(test.drop(columns=['loan_status']))[:,1]\r\n",
        "    \r\n",
        "    \r\n",
        "    loss_train = metrics.log_loss(train_df['loan_status'],ytrain)\r\n",
        "    loss_eval = metrics.log_loss(eval_df['loan_status'],yeval)\r\n",
        "    loss_test = metrics.log_loss(test['loan_status'],ytest)\r\n",
        "    print('train logloss',loss_train, 'eval logloss',loss_eval, 'test logloss',loss_test )\r\n",
        "    \r\n",
        "    loss_train_list.append(loss_train)\r\n",
        "    loss_eval_list.append(loss_eval)\r\n",
        "    loss_test_list.append(loss_test)\r\n",
        "\r\n",
        "    ytrainL = getLabel(ytrain)\r\n",
        "    yevalL = getLabel(yeval)\r\n",
        "    ytestL = getLabel(ytest)\r\n",
        "    print(\"train classification report\")\r\n",
        "    print(metrics.classification_report(train_df['loan_status'],ytrainL))\r\n",
        "    print(\"**********metrics**************\")\r\n",
        "    print(\"val classification report\")\r\n",
        "    print(metrics.classification_report(eval_df['loan_status'],yevalL))\r\n",
        "    print(\"***********classification****************\")\r\n",
        "    print(\"target classification report\")\r\n",
        "    print(metrics.classification_report(test['loan_status'],ytestL))\r\n",
        "    print(\"****************report**********************\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[20]\ttrain's binary_logloss: 0.204217\tval's binary_logloss: 0.213604\n",
            "[40]\ttrain's binary_logloss: 0.17979\tval's binary_logloss: 0.199146\n",
            "[60]\ttrain's binary_logloss: 0.168875\tval's binary_logloss: 0.198759\n",
            "[80]\ttrain's binary_logloss: 0.160312\tval's binary_logloss: 0.198661\n",
            "[100]\ttrain's binary_logloss: 0.153623\tval's binary_logloss: 0.199181\n",
            "train logloss 0.15362316367975015 eval logloss 0.19918081167439325 test logloss 0.1993030345536531\n",
            "train classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.84      8149\n",
            "           1       0.96      0.96      0.96     31851\n",
            "\n",
            "    accuracy                           0.94     40000\n",
            "   macro avg       0.90      0.90      0.90     40000\n",
            "weighted avg       0.94      0.94      0.94     40000\n",
            "\n",
            "**********metrics**************\n",
            "val classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.82      0.81      2063\n",
            "           1       0.95      0.94      0.95      7937\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.87      0.88      0.88     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "***********classification****************\n",
            "target classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.81      0.79      9774\n",
            "           1       0.95      0.94      0.95     40226\n",
            "\n",
            "    accuracy                           0.92     50000\n",
            "   macro avg       0.86      0.88      0.87     50000\n",
            "weighted avg       0.92      0.92      0.92     50000\n",
            "\n",
            "****************report**********************\n",
            "[20]\ttrain's binary_logloss: 0.20407\tval's binary_logloss: 0.214672\n",
            "[40]\ttrain's binary_logloss: 0.1799\tval's binary_logloss: 0.199177\n",
            "[60]\ttrain's binary_logloss: 0.168765\tval's binary_logloss: 0.198797\n",
            "[80]\ttrain's binary_logloss: 0.160834\tval's binary_logloss: 0.199459\n",
            "[100]\ttrain's binary_logloss: 0.1541\tval's binary_logloss: 0.199721\n",
            "train logloss 0.15410045112303186 eval logloss 0.19972066603574234 test logloss 0.2002115727590769\n",
            "train classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.84      8137\n",
            "           1       0.96      0.96      0.96     31863\n",
            "\n",
            "    accuracy                           0.94     40000\n",
            "   macro avg       0.90      0.90      0.90     40000\n",
            "weighted avg       0.94      0.94      0.94     40000\n",
            "\n",
            "**********metrics**************\n",
            "val classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.79      0.80      2075\n",
            "           1       0.95      0.95      0.95      7925\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.88      0.87      0.87     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "***********classification****************\n",
            "target classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.80      0.79      9774\n",
            "           1       0.95      0.94      0.95     40226\n",
            "\n",
            "    accuracy                           0.92     50000\n",
            "   macro avg       0.86      0.87      0.87     50000\n",
            "weighted avg       0.92      0.92      0.92     50000\n",
            "\n",
            "****************report**********************\n",
            "[20]\ttrain's binary_logloss: 0.203272\tval's binary_logloss: 0.216699\n",
            "[40]\ttrain's binary_logloss: 0.179108\tval's binary_logloss: 0.203458\n",
            "[60]\ttrain's binary_logloss: 0.167769\tval's binary_logloss: 0.203313\n",
            "[80]\ttrain's binary_logloss: 0.159793\tval's binary_logloss: 0.203883\n",
            "[100]\ttrain's binary_logloss: 0.153354\tval's binary_logloss: 0.204133\n",
            "train logloss 0.15335350291550334 eval logloss 0.20413253281901775 test logloss 0.19926262045201568\n",
            "train classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.85      8179\n",
            "           1       0.96      0.96      0.96     31821\n",
            "\n",
            "    accuracy                           0.94     40000\n",
            "   macro avg       0.90      0.91      0.90     40000\n",
            "weighted avg       0.94      0.94      0.94     40000\n",
            "\n",
            "**********metrics**************\n",
            "val classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.79      0.79      2033\n",
            "           1       0.95      0.95      0.95      7967\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "***********classification****************\n",
            "target classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.79      9774\n",
            "           1       0.95      0.94      0.95     40226\n",
            "\n",
            "    accuracy                           0.92     50000\n",
            "   macro avg       0.87      0.88      0.87     50000\n",
            "weighted avg       0.92      0.92      0.92     50000\n",
            "\n",
            "****************report**********************\n",
            "[20]\ttrain's binary_logloss: 0.205841\tval's binary_logloss: 0.209318\n",
            "[40]\ttrain's binary_logloss: 0.18189\tval's binary_logloss: 0.193744\n",
            "[60]\ttrain's binary_logloss: 0.170859\tval's binary_logloss: 0.193189\n",
            "[80]\ttrain's binary_logloss: 0.162791\tval's binary_logloss: 0.194024\n",
            "[100]\ttrain's binary_logloss: 0.155717\tval's binary_logloss: 0.194961\n",
            "train logloss 0.15571675605963842 eval logloss 0.19496081935137277 test logloss 0.1998454790055626\n",
            "train classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.85      0.84      8172\n",
            "           1       0.96      0.96      0.96     31828\n",
            "\n",
            "    accuracy                           0.93     40000\n",
            "   macro avg       0.90      0.90      0.90     40000\n",
            "weighted avg       0.93      0.93      0.93     40000\n",
            "\n",
            "**********metrics**************\n",
            "val classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.81      0.81      2040\n",
            "           1       0.95      0.95      0.95      7960\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "***********classification****************\n",
            "target classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.79      9774\n",
            "           1       0.95      0.94      0.95     40226\n",
            "\n",
            "    accuracy                           0.92     50000\n",
            "   macro avg       0.86      0.87      0.87     50000\n",
            "weighted avg       0.92      0.92      0.92     50000\n",
            "\n",
            "****************report**********************\n",
            "[20]\ttrain's binary_logloss: 0.204976\tval's binary_logloss: 0.211581\n",
            "[40]\ttrain's binary_logloss: 0.180802\tval's binary_logloss: 0.197119\n",
            "[60]\ttrain's binary_logloss: 0.170522\tval's binary_logloss: 0.196261\n",
            "[80]\ttrain's binary_logloss: 0.161783\tval's binary_logloss: 0.197027\n",
            "[100]\ttrain's binary_logloss: 0.154631\tval's binary_logloss: 0.197167\n",
            "train logloss 0.15463099281248935 eval logloss 0.19716683890622008 test logloss 0.2002067631615874\n",
            "train classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.85      0.84      8211\n",
            "           1       0.96      0.96      0.96     31789\n",
            "\n",
            "    accuracy                           0.93     40000\n",
            "   macro avg       0.90      0.90      0.90     40000\n",
            "weighted avg       0.93      0.93      0.93     40000\n",
            "\n",
            "**********metrics**************\n",
            "val classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.82      0.80      2001\n",
            "           1       0.95      0.95      0.95      7999\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.87      0.88      0.88     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "***********classification****************\n",
            "target classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.79      9774\n",
            "           1       0.95      0.94      0.95     40226\n",
            "\n",
            "    accuracy                           0.92     50000\n",
            "   macro avg       0.87      0.88      0.87     50000\n",
            "weighted avg       0.92      0.92      0.92     50000\n",
            "\n",
            "****************report**********************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPPsCwJ9hx4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df1525ba-3d6d-4b9f-ef40-9480cc7abd49"
      },
      "source": [
        "print('avg train loss', np.mean(loss_train_list),'avg eval loss', \r\n",
        "      np.mean(loss_eval_list),'avg test loss', np.mean(loss_test_list))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avg train loss 0.1542849733180826 avg eval loss 0.19903233375734924 avg test loss 0.19976589398637914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt1cTA_gh3ho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "867b7a2f-2834-4277-b076-65e2c5d2aabe"
      },
      "source": [
        "#baseline 调参： 把beseline进行了调参\r\n",
        "#并且打印出了feature的重要性\r\n",
        "\r\n",
        "train_copy = train.copy()\r\n",
        "folds = KFold(n_splits=5,shuffle=True, random_state=42)\r\n",
        "loss_train_list = []\r\n",
        "loss_eval_list = []\r\n",
        "loss_test_list = []\r\n",
        "key_cols = []\r\n",
        "    \r\n",
        "for train_ix, eval_ix in folds.split(train_copy):\r\n",
        "    train_df = train_copy.loc[train_ix]\r\n",
        "    eval_df = train_copy.loc[eval_ix]\r\n",
        "    \r\n",
        "    clf = lgb.LGBMClassifier(boosting_type='gbdt', \r\n",
        "          objective =\"binary\",\r\n",
        "          metric= 'binary_logloss',\r\n",
        "          colsample_bytree =0.7, \r\n",
        "          learning_rate = 0.02, \r\n",
        "          n_estimators = 300,\r\n",
        "          num_leaves = 31, \r\n",
        "          subsample =0.7,\r\n",
        "          importance_type ='gain'\r\n",
        "          ).fit(train_df.drop(columns=['loan_status']), train_df['loan_status'],\r\n",
        "                eval_names=[\"train\",\"val\"],\r\n",
        "                eval_set=[(train_df.drop(columns=['loan_status']), train_df['loan_status']),\r\n",
        "                          (eval_df.drop(columns=['loan_status']), eval_df['loan_status'])],\r\n",
        "                eval_metric='binary_logloss',\r\n",
        "                verbose=20)\r\n",
        "    \r\n",
        "    ytrain = clf.predict_proba(train_df.drop(columns=['loan_status']))[:,1]\r\n",
        "    yeval = clf.predict_proba(eval_df.drop(columns=['loan_status']))[:,1]\r\n",
        "    ytest = clf.predict_proba(test.drop(columns=['loan_status']))[:,1]\r\n",
        "    \r\n",
        "    \r\n",
        "    loss_train = metrics.log_loss(train_df['loan_status'],ytrain)\r\n",
        "    loss_eval = metrics.log_loss(eval_df['loan_status'],yeval)\r\n",
        "    loss_test = metrics.log_loss(test['loan_status'],ytest)\r\n",
        "    print('train logloss',loss_train, 'eval logloss',loss_eval, 'test logloss',loss_test )\r\n",
        "    \r\n",
        "    loss_train_list.append(loss_train)\r\n",
        "    loss_eval_list.append(loss_eval)\r\n",
        "    loss_test_list.append(loss_test)\r\n",
        "\r\n",
        "    ytrainL = getLabel(ytrain)\r\n",
        "    yevalL = getLabel(yeval)\r\n",
        "    ytestL = getLabel(ytest)\r\n",
        "    print(\"train classification report\")\r\n",
        "    print(metrics.classification_report(train_df['loan_status'],ytrainL))\r\n",
        "    print(\"******classification_report1.*******\")\r\n",
        "    print(\"val classification report\")\r\n",
        "    print(metrics.classification_report(eval_df['loan_status'],yevalL))\r\n",
        "    print(\"******classification_report2.*******\")\r\n",
        "    print(\"target classification report\")\r\n",
        "    print(metrics.classification_report(test['loan_status'],ytestL))\r\n",
        "    print(\"******classification_report3.*******\")\r\n",
        "    \r\n",
        "    feature_importance = pd.DataFrame({'feature_name': clf.booster_.feature_name(),\r\n",
        "                                       'importance': clf.feature_importances_})\r\n",
        "    feature_importance.sort_index(ascending=False, inplace=True)\r\n",
        "    print(feature_importance[:30])\r\n",
        "    for c in feature_importance[:30]['feature_name']:\r\n",
        "        key_cols.append(c)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[20]\ttrain's binary_logloss: 0.357411\tval's binary_logloss: 0.36073\n",
            "[40]\ttrain's binary_logloss: 0.287821\tval's binary_logloss: 0.29192\n",
            "[60]\ttrain's binary_logloss: 0.247249\tval's binary_logloss: 0.252545\n",
            "[80]\ttrain's binary_logloss: 0.223145\tval's binary_logloss: 0.229981\n",
            "[100]\ttrain's binary_logloss: 0.208243\tval's binary_logloss: 0.216939\n",
            "[120]\ttrain's binary_logloss: 0.19877\tval's binary_logloss: 0.209185\n",
            "[140]\ttrain's binary_logloss: 0.19253\tval's binary_logloss: 0.204743\n",
            "[160]\ttrain's binary_logloss: 0.187994\tval's binary_logloss: 0.202065\n",
            "[180]\ttrain's binary_logloss: 0.184568\tval's binary_logloss: 0.20052\n",
            "[200]\ttrain's binary_logloss: 0.181662\tval's binary_logloss: 0.199447\n",
            "[220]\ttrain's binary_logloss: 0.179092\tval's binary_logloss: 0.198802\n",
            "[240]\ttrain's binary_logloss: 0.176879\tval's binary_logloss: 0.198553\n",
            "[260]\ttrain's binary_logloss: 0.17463\tval's binary_logloss: 0.19836\n",
            "[280]\ttrain's binary_logloss: 0.172598\tval's binary_logloss: 0.198172\n",
            "[300]\ttrain's binary_logloss: 0.170686\tval's binary_logloss: 0.198027\n",
            "train logloss 0.17068580012176388 eval logloss 0.19802662180195194 test logloss 0.19744842522087597\n",
            "train classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83      8149\n",
            "           1       0.96      0.95      0.96     31851\n",
            "\n",
            "    accuracy                           0.93     40000\n",
            "   macro avg       0.89      0.90      0.89     40000\n",
            "weighted avg       0.93      0.93      0.93     40000\n",
            "\n",
            "******classification_report1.*******\n",
            "val classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.82      0.81      2063\n",
            "           1       0.95      0.94      0.95      7937\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.87      0.88      0.88     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "******classification_report2.*******\n",
            "target classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.79      9774\n",
            "           1       0.95      0.94      0.95     40226\n",
            "\n",
            "    accuracy                           0.92     50000\n",
            "   macro avg       0.87      0.88      0.87     50000\n",
            "weighted avg       0.92      0.92      0.92     50000\n",
            "\n",
            "******classification_report3.*******\n",
            "                      feature_name  importance\n",
            "144        discrete_term_2_one_hot    7956.854\n",
            "143        discrete_term_1_one_hot   20194.088\n",
            "142  discrete_sub_grade_35_one_hot       0.000\n",
            "141  discrete_sub_grade_34_one_hot       5.624\n",
            "140  discrete_sub_grade_33_one_hot       0.000\n",
            "139  discrete_sub_grade_32_one_hot       0.000\n",
            "138  discrete_sub_grade_31_one_hot       0.000\n",
            "137  discrete_sub_grade_30_one_hot       0.000\n",
            "136  discrete_sub_grade_29_one_hot      32.616\n",
            "135  discrete_sub_grade_28_one_hot      12.212\n",
            "134  discrete_sub_grade_27_one_hot       5.848\n",
            "133  discrete_sub_grade_26_one_hot      64.445\n",
            "132  discrete_sub_grade_25_one_hot     157.189\n",
            "131  discrete_sub_grade_24_one_hot     127.347\n",
            "130  discrete_sub_grade_23_one_hot      23.924\n",
            "129  discrete_sub_grade_22_one_hot      37.407\n",
            "128  discrete_sub_grade_21_one_hot      26.930\n",
            "127  discrete_sub_grade_20_one_hot       0.000\n",
            "126  discrete_sub_grade_19_one_hot      97.245\n",
            "125  discrete_sub_grade_18_one_hot      86.918\n",
            "124  discrete_sub_grade_17_one_hot       5.091\n",
            "123  discrete_sub_grade_16_one_hot      92.898\n",
            "122  discrete_sub_grade_15_one_hot      20.113\n",
            "121  discrete_sub_grade_14_one_hot     114.862\n",
            "120  discrete_sub_grade_13_one_hot     119.996\n",
            "119  discrete_sub_grade_12_one_hot      88.224\n",
            "118  discrete_sub_grade_11_one_hot      11.155\n",
            "117  discrete_sub_grade_10_one_hot     160.844\n",
            "116   discrete_sub_grade_9_one_hot     182.341\n",
            "115   discrete_sub_grade_8_one_hot       4.536\n",
            "[20]\ttrain's binary_logloss: 0.35706\tval's binary_logloss: 0.363682\n",
            "[40]\ttrain's binary_logloss: 0.287565\tval's binary_logloss: 0.294952\n",
            "[60]\ttrain's binary_logloss: 0.247003\tval's binary_logloss: 0.255152\n",
            "[80]\ttrain's binary_logloss: 0.223051\tval's binary_logloss: 0.232118\n",
            "[100]\ttrain's binary_logloss: 0.208251\tval's binary_logloss: 0.218376\n",
            "[120]\ttrain's binary_logloss: 0.198762\tval's binary_logloss: 0.210212\n",
            "[140]\ttrain's binary_logloss: 0.192619\tval's binary_logloss: 0.205448\n",
            "[160]\ttrain's binary_logloss: 0.188139\tval's binary_logloss: 0.20249\n",
            "[180]\ttrain's binary_logloss: 0.184826\tval's binary_logloss: 0.200793\n",
            "[200]\ttrain's binary_logloss: 0.181936\tval's binary_logloss: 0.199645\n",
            "[220]\ttrain's binary_logloss: 0.179387\tval's binary_logloss: 0.198943\n",
            "[240]\ttrain's binary_logloss: 0.176947\tval's binary_logloss: 0.198626\n",
            "[260]\ttrain's binary_logloss: 0.174801\tval's binary_logloss: 0.19842\n",
            "[280]\ttrain's binary_logloss: 0.172747\tval's binary_logloss: 0.198204\n",
            "[300]\ttrain's binary_logloss: 0.170919\tval's binary_logloss: 0.198133\n",
            "train logloss 0.1709186810550537 eval logloss 0.19813271926406223 test logloss 0.19808945813621173\n",
            "train classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83      8137\n",
            "           1       0.96      0.95      0.96     31863\n",
            "\n",
            "    accuracy                           0.93     40000\n",
            "   macro avg       0.89      0.90      0.89     40000\n",
            "weighted avg       0.93      0.93      0.93     40000\n",
            "\n",
            "******classification_report1.*******\n",
            "val classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.80      0.80      2075\n",
            "           1       0.95      0.95      0.95      7925\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.88      0.87      0.87     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "******classification_report2.*******\n",
            "target classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.80      0.79      9774\n",
            "           1       0.95      0.95      0.95     40226\n",
            "\n",
            "    accuracy                           0.92     50000\n",
            "   macro avg       0.87      0.87      0.87     50000\n",
            "weighted avg       0.92      0.92      0.92     50000\n",
            "\n",
            "******classification_report3.*******\n",
            "                      feature_name  importance\n",
            "144        discrete_term_2_one_hot    7912.401\n",
            "143        discrete_term_1_one_hot   20422.009\n",
            "142  discrete_sub_grade_35_one_hot       0.000\n",
            "141  discrete_sub_grade_34_one_hot       5.826\n",
            "140  discrete_sub_grade_33_one_hot       0.000\n",
            "139  discrete_sub_grade_32_one_hot       0.000\n",
            "138  discrete_sub_grade_31_one_hot       0.000\n",
            "137  discrete_sub_grade_30_one_hot       0.000\n",
            "136  discrete_sub_grade_29_one_hot       5.061\n",
            "135  discrete_sub_grade_28_one_hot      10.829\n",
            "134  discrete_sub_grade_27_one_hot       0.000\n",
            "133  discrete_sub_grade_26_one_hot      76.677\n",
            "132  discrete_sub_grade_25_one_hot      53.082\n",
            "131  discrete_sub_grade_24_one_hot      29.080\n",
            "130  discrete_sub_grade_23_one_hot       0.000\n",
            "129  discrete_sub_grade_22_one_hot      36.719\n",
            "128  discrete_sub_grade_21_one_hot       5.933\n",
            "127  discrete_sub_grade_20_one_hot      49.971\n",
            "126  discrete_sub_grade_19_one_hot      94.189\n",
            "125  discrete_sub_grade_18_one_hot     191.337\n",
            "124  discrete_sub_grade_17_one_hot       0.000\n",
            "123  discrete_sub_grade_16_one_hot      44.621\n",
            "122  discrete_sub_grade_15_one_hot       0.000\n",
            "121  discrete_sub_grade_14_one_hot      48.320\n",
            "120  discrete_sub_grade_13_one_hot      68.203\n",
            "119  discrete_sub_grade_12_one_hot      71.330\n",
            "118  discrete_sub_grade_11_one_hot      14.997\n",
            "117  discrete_sub_grade_10_one_hot     170.639\n",
            "116   discrete_sub_grade_9_one_hot     200.622\n",
            "115   discrete_sub_grade_8_one_hot      31.951\n",
            "[20]\ttrain's binary_logloss: 0.357549\tval's binary_logloss: 0.360881\n",
            "[40]\ttrain's binary_logloss: 0.287451\tval's binary_logloss: 0.293632\n",
            "[60]\ttrain's binary_logloss: 0.246584\tval's binary_logloss: 0.255047\n",
            "[80]\ttrain's binary_logloss: 0.222463\tval's binary_logloss: 0.233006\n",
            "[100]\ttrain's binary_logloss: 0.207528\tval's binary_logloss: 0.220108\n",
            "[120]\ttrain's binary_logloss: 0.198014\tval's binary_logloss: 0.212371\n",
            "[140]\ttrain's binary_logloss: 0.191859\tval's binary_logloss: 0.207972\n",
            "[160]\ttrain's binary_logloss: 0.187383\tval's binary_logloss: 0.205325\n",
            "[180]\ttrain's binary_logloss: 0.183929\tval's binary_logloss: 0.203772\n",
            "[200]\ttrain's binary_logloss: 0.181071\tval's binary_logloss: 0.202927\n",
            "[220]\ttrain's binary_logloss: 0.17855\tval's binary_logloss: 0.202442\n",
            "[240]\ttrain's binary_logloss: 0.176162\tval's binary_logloss: 0.202209\n",
            "[260]\ttrain's binary_logloss: 0.173934\tval's binary_logloss: 0.201986\n",
            "[280]\ttrain's binary_logloss: 0.171773\tval's binary_logloss: 0.202077\n",
            "[300]\ttrain's binary_logloss: 0.169811\tval's binary_logloss: 0.201945\n",
            "train logloss 0.1698110569784344 eval logloss 0.2019448605938826 test logloss 0.19728576028160383\n",
            "train classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83      8179\n",
            "           1       0.96      0.95      0.96     31821\n",
            "\n",
            "    accuracy                           0.93     40000\n",
            "   macro avg       0.89      0.90      0.89     40000\n",
            "weighted avg       0.93      0.93      0.93     40000\n",
            "\n",
            "******classification_report1.*******\n",
            "val classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80      2033\n",
            "           1       0.95      0.95      0.95      7967\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "******classification_report2.*******\n",
            "target classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.79      9774\n",
            "           1       0.95      0.94      0.95     40226\n",
            "\n",
            "    accuracy                           0.92     50000\n",
            "   macro avg       0.87      0.88      0.87     50000\n",
            "weighted avg       0.92      0.92      0.92     50000\n",
            "\n",
            "******classification_report3.*******\n",
            "                      feature_name  importance\n",
            "144        discrete_term_2_one_hot    7654.089\n",
            "143        discrete_term_1_one_hot   19859.213\n",
            "142  discrete_sub_grade_35_one_hot       0.000\n",
            "141  discrete_sub_grade_34_one_hot       0.000\n",
            "140  discrete_sub_grade_33_one_hot       0.000\n",
            "139  discrete_sub_grade_32_one_hot       0.000\n",
            "138  discrete_sub_grade_31_one_hot       0.000\n",
            "137  discrete_sub_grade_30_one_hot       0.000\n",
            "136  discrete_sub_grade_29_one_hot      18.604\n",
            "135  discrete_sub_grade_28_one_hot      21.115\n",
            "134  discrete_sub_grade_27_one_hot       0.000\n",
            "133  discrete_sub_grade_26_one_hot      32.560\n",
            "132  discrete_sub_grade_25_one_hot     216.423\n",
            "131  discrete_sub_grade_24_one_hot      91.812\n",
            "130  discrete_sub_grade_23_one_hot      30.056\n",
            "129  discrete_sub_grade_22_one_hot      27.188\n",
            "128  discrete_sub_grade_21_one_hot       0.000\n",
            "127  discrete_sub_grade_20_one_hot      48.388\n",
            "126  discrete_sub_grade_19_one_hot     157.185\n",
            "125  discrete_sub_grade_18_one_hot     140.437\n",
            "124  discrete_sub_grade_17_one_hot       0.000\n",
            "123  discrete_sub_grade_16_one_hot      53.110\n",
            "122  discrete_sub_grade_15_one_hot      23.234\n",
            "121  discrete_sub_grade_14_one_hot     109.457\n",
            "120  discrete_sub_grade_13_one_hot     178.408\n",
            "119  discrete_sub_grade_12_one_hot      23.945\n",
            "118  discrete_sub_grade_11_one_hot      54.935\n",
            "117  discrete_sub_grade_10_one_hot     158.819\n",
            "116   discrete_sub_grade_9_one_hot     243.032\n",
            "115   discrete_sub_grade_8_one_hot      62.421\n",
            "[20]\ttrain's binary_logloss: 0.35446\tval's binary_logloss: 0.354022\n",
            "[40]\ttrain's binary_logloss: 0.28677\tval's binary_logloss: 0.287059\n",
            "[60]\ttrain's binary_logloss: 0.246045\tval's binary_logloss: 0.247024\n",
            "[80]\ttrain's binary_logloss: 0.222493\tval's binary_logloss: 0.224442\n",
            "[100]\ttrain's binary_logloss: 0.20826\tval's binary_logloss: 0.211357\n",
            "[120]\ttrain's binary_logloss: 0.199223\tval's binary_logloss: 0.203654\n",
            "[140]\ttrain's binary_logloss: 0.193501\tval's binary_logloss: 0.199381\n",
            "[160]\ttrain's binary_logloss: 0.189286\tval's binary_logloss: 0.196532\n",
            "[180]\ttrain's binary_logloss: 0.185928\tval's binary_logloss: 0.194834\n",
            "[200]\ttrain's binary_logloss: 0.183069\tval's binary_logloss: 0.193817\n",
            "[220]\ttrain's binary_logloss: 0.180676\tval's binary_logloss: 0.193366\n",
            "[240]\ttrain's binary_logloss: 0.178244\tval's binary_logloss: 0.192899\n",
            "[260]\ttrain's binary_logloss: 0.175939\tval's binary_logloss: 0.192553\n",
            "[280]\ttrain's binary_logloss: 0.173869\tval's binary_logloss: 0.192421\n",
            "[300]\ttrain's binary_logloss: 0.172023\tval's binary_logloss: 0.192339\n",
            "train logloss 0.17202276306829345 eval logloss 0.19233859391741986 test logloss 0.19782453268714445\n",
            "train classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.83      0.83      8172\n",
            "           1       0.96      0.95      0.96     31828\n",
            "\n",
            "    accuracy                           0.93     40000\n",
            "   macro avg       0.89      0.89      0.89     40000\n",
            "weighted avg       0.93      0.93      0.93     40000\n",
            "\n",
            "******classification_report1.*******\n",
            "val classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.82      0.81      2040\n",
            "           1       0.95      0.95      0.95      7960\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "******classification_report2.*******\n",
            "target classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.79      9774\n",
            "           1       0.95      0.94      0.95     40226\n",
            "\n",
            "    accuracy                           0.92     50000\n",
            "   macro avg       0.86      0.88      0.87     50000\n",
            "weighted avg       0.92      0.92      0.92     50000\n",
            "\n",
            "******classification_report3.*******\n",
            "                      feature_name  importance\n",
            "144        discrete_term_2_one_hot    9683.134\n",
            "143        discrete_term_1_one_hot   17101.807\n",
            "142  discrete_sub_grade_35_one_hot       0.000\n",
            "141  discrete_sub_grade_34_one_hot       0.000\n",
            "140  discrete_sub_grade_33_one_hot       0.000\n",
            "139  discrete_sub_grade_32_one_hot       0.000\n",
            "138  discrete_sub_grade_31_one_hot       0.000\n",
            "137  discrete_sub_grade_30_one_hot       0.000\n",
            "136  discrete_sub_grade_29_one_hot       9.995\n",
            "135  discrete_sub_grade_28_one_hot      26.095\n",
            "134  discrete_sub_grade_27_one_hot       0.000\n",
            "133  discrete_sub_grade_26_one_hot      46.315\n",
            "132  discrete_sub_grade_25_one_hot     176.243\n",
            "131  discrete_sub_grade_24_one_hot      92.348\n",
            "130  discrete_sub_grade_23_one_hot      74.183\n",
            "129  discrete_sub_grade_22_one_hot       6.265\n",
            "128  discrete_sub_grade_21_one_hot      68.858\n",
            "127  discrete_sub_grade_20_one_hot      64.261\n",
            "126  discrete_sub_grade_19_one_hot      94.624\n",
            "125  discrete_sub_grade_18_one_hot     187.053\n",
            "124  discrete_sub_grade_17_one_hot       0.000\n",
            "123  discrete_sub_grade_16_one_hot      26.646\n",
            "122  discrete_sub_grade_15_one_hot      15.224\n",
            "121  discrete_sub_grade_14_one_hot      67.175\n",
            "120  discrete_sub_grade_13_one_hot     130.642\n",
            "119  discrete_sub_grade_12_one_hot      63.680\n",
            "118  discrete_sub_grade_11_one_hot       0.000\n",
            "117  discrete_sub_grade_10_one_hot     190.286\n",
            "116   discrete_sub_grade_9_one_hot      74.129\n",
            "115   discrete_sub_grade_8_one_hot      23.288\n",
            "[20]\ttrain's binary_logloss: 0.354933\tval's binary_logloss: 0.352202\n",
            "[40]\ttrain's binary_logloss: 0.286898\tval's binary_logloss: 0.286469\n",
            "[60]\ttrain's binary_logloss: 0.245884\tval's binary_logloss: 0.247594\n",
            "[80]\ttrain's binary_logloss: 0.222089\tval's binary_logloss: 0.225788\n",
            "[100]\ttrain's binary_logloss: 0.207726\tval's binary_logloss: 0.213193\n",
            "[120]\ttrain's binary_logloss: 0.19862\tval's binary_logloss: 0.205884\n",
            "[140]\ttrain's binary_logloss: 0.19283\tval's binary_logloss: 0.201863\n",
            "[160]\ttrain's binary_logloss: 0.188604\tval's binary_logloss: 0.199354\n",
            "[180]\ttrain's binary_logloss: 0.185251\tval's binary_logloss: 0.197755\n",
            "[200]\ttrain's binary_logloss: 0.182436\tval's binary_logloss: 0.196617\n",
            "[220]\ttrain's binary_logloss: 0.179994\tval's binary_logloss: 0.196038\n",
            "[240]\ttrain's binary_logloss: 0.177692\tval's binary_logloss: 0.195737\n",
            "[260]\ttrain's binary_logloss: 0.175595\tval's binary_logloss: 0.195611\n",
            "[280]\ttrain's binary_logloss: 0.173738\tval's binary_logloss: 0.195307\n",
            "[300]\ttrain's binary_logloss: 0.171789\tval's binary_logloss: 0.195239\n",
            "train logloss 0.17178910429757435 eval logloss 0.19523940804931722 test logloss 0.19786743220177438\n",
            "train classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83      8211\n",
            "           1       0.96      0.95      0.96     31789\n",
            "\n",
            "    accuracy                           0.93     40000\n",
            "   macro avg       0.89      0.90      0.89     40000\n",
            "weighted avg       0.93      0.93      0.93     40000\n",
            "\n",
            "******classification_report1.*******\n",
            "val classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.82      0.80      2001\n",
            "           1       0.95      0.95      0.95      7999\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.87      0.88      0.88     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "******classification_report2.*******\n",
            "target classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.79      9774\n",
            "           1       0.95      0.94      0.95     40226\n",
            "\n",
            "    accuracy                           0.92     50000\n",
            "   macro avg       0.87      0.88      0.87     50000\n",
            "weighted avg       0.92      0.92      0.92     50000\n",
            "\n",
            "******classification_report3.*******\n",
            "                      feature_name  importance\n",
            "144        discrete_term_2_one_hot    9644.436\n",
            "143        discrete_term_1_one_hot   17181.235\n",
            "142  discrete_sub_grade_35_one_hot       0.000\n",
            "141  discrete_sub_grade_34_one_hot       0.000\n",
            "140  discrete_sub_grade_33_one_hot       0.000\n",
            "139  discrete_sub_grade_32_one_hot       0.000\n",
            "138  discrete_sub_grade_31_one_hot       0.000\n",
            "137  discrete_sub_grade_30_one_hot       0.000\n",
            "136  discrete_sub_grade_29_one_hot       5.782\n",
            "135  discrete_sub_grade_28_one_hot       4.779\n",
            "134  discrete_sub_grade_27_one_hot       0.000\n",
            "133  discrete_sub_grade_26_one_hot      27.222\n",
            "132  discrete_sub_grade_25_one_hot     279.399\n",
            "131  discrete_sub_grade_24_one_hot      81.340\n",
            "130  discrete_sub_grade_23_one_hot       0.000\n",
            "129  discrete_sub_grade_22_one_hot      40.129\n",
            "128  discrete_sub_grade_21_one_hot      18.376\n",
            "127  discrete_sub_grade_20_one_hot      58.078\n",
            "126  discrete_sub_grade_19_one_hot      85.052\n",
            "125  discrete_sub_grade_18_one_hot     138.669\n",
            "124  discrete_sub_grade_17_one_hot       0.000\n",
            "123  discrete_sub_grade_16_one_hot      25.265\n",
            "122  discrete_sub_grade_15_one_hot      24.294\n",
            "121  discrete_sub_grade_14_one_hot      49.408\n",
            "120  discrete_sub_grade_13_one_hot      43.744\n",
            "119  discrete_sub_grade_12_one_hot      43.557\n",
            "118  discrete_sub_grade_11_one_hot      32.675\n",
            "117  discrete_sub_grade_10_one_hot     142.320\n",
            "116   discrete_sub_grade_9_one_hot     104.002\n",
            "115   discrete_sub_grade_8_one_hot      20.043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1Yo62PvktbG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7452f6a5-e691-48df-aab9-68a2e92398ed"
      },
      "source": [
        "print('avg train loss', np.mean(loss_train_list),'avg eval loss', \r\n",
        "      np.mean(loss_eval_list),'avg test loss', np.mean(loss_test_list))\r\n",
        "\r\n",
        "\r\n",
        "baseline_train_avgloss = np.mean(loss_train_list)\r\n",
        "baseline_eval_avgloss = np.mean(loss_eval_list)\r\n",
        "baseline_test_avgloss = np.mean(loss_test_list)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avg train loss 0.17104548110422396 avg eval loss 0.19713644072532674 avg test loss 0.19770312170552207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0etxOfVlSPx"
      },
      "source": [
        "# **计算特征 把特征重要性的前30的特征进行了组合**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1Wuvb4IlRO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be1550da-2bfc-44d4-f3ee-3c59c5517451"
      },
      "source": [
        "set(key_cols)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'discrete_sub_grade_10_one_hot',\n",
              " 'discrete_sub_grade_11_one_hot',\n",
              " 'discrete_sub_grade_12_one_hot',\n",
              " 'discrete_sub_grade_13_one_hot',\n",
              " 'discrete_sub_grade_14_one_hot',\n",
              " 'discrete_sub_grade_15_one_hot',\n",
              " 'discrete_sub_grade_16_one_hot',\n",
              " 'discrete_sub_grade_17_one_hot',\n",
              " 'discrete_sub_grade_18_one_hot',\n",
              " 'discrete_sub_grade_19_one_hot',\n",
              " 'discrete_sub_grade_20_one_hot',\n",
              " 'discrete_sub_grade_21_one_hot',\n",
              " 'discrete_sub_grade_22_one_hot',\n",
              " 'discrete_sub_grade_23_one_hot',\n",
              " 'discrete_sub_grade_24_one_hot',\n",
              " 'discrete_sub_grade_25_one_hot',\n",
              " 'discrete_sub_grade_26_one_hot',\n",
              " 'discrete_sub_grade_27_one_hot',\n",
              " 'discrete_sub_grade_28_one_hot',\n",
              " 'discrete_sub_grade_29_one_hot',\n",
              " 'discrete_sub_grade_30_one_hot',\n",
              " 'discrete_sub_grade_31_one_hot',\n",
              " 'discrete_sub_grade_32_one_hot',\n",
              " 'discrete_sub_grade_33_one_hot',\n",
              " 'discrete_sub_grade_34_one_hot',\n",
              " 'discrete_sub_grade_35_one_hot',\n",
              " 'discrete_sub_grade_8_one_hot',\n",
              " 'discrete_sub_grade_9_one_hot',\n",
              " 'discrete_term_1_one_hot',\n",
              " 'discrete_term_2_one_hot'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5kb8R_nlYb1"
      },
      "source": [
        "continoue_cols = ['continuous_annual_inc',\r\n",
        " 'continuous_delinq_2yrs',\r\n",
        " 'continuous_dti',\r\n",
        " 'continuous_fico_range_high',\r\n",
        " 'continuous_fico_range_low',\r\n",
        " 'continuous_funded_amnt',\r\n",
        " 'continuous_funded_amnt_inv',\r\n",
        " 'continuous_inq_last_6mths',\r\n",
        " 'continuous_installment',\r\n",
        " 'continuous_int_rate',\r\n",
        " 'continuous_last_fico_range_high',\r\n",
        " 'continuous_last_fico_range_low',\r\n",
        " 'continuous_loan_amnt',\r\n",
        " 'continuous_mths_since_last_delinq',\r\n",
        " 'continuous_mths_since_last_major_derog',\r\n",
        " 'continuous_mths_since_last_record',\r\n",
        " 'continuous_open_acc',\r\n",
        " 'continuous_pub_rec',]\r\n",
        "\r\n",
        "discrete_cols = ['discrete_addr_state_11_one_hot',\r\n",
        " 'discrete_addr_state_14_one_hot',\r\n",
        " 'discrete_addr_state_15_one_hot',\r\n",
        " 'discrete_addr_state_36_one_hot',\r\n",
        " 'discrete_addr_state_37_one_hot',\r\n",
        " 'discrete_addr_state_3_one_hot',\r\n",
        " 'discrete_addr_state_43_one_hot',\r\n",
        " 'discrete_addr_state_4_one_hot',\r\n",
        " 'discrete_addr_state_9_one_hot',\r\n",
        " 'discrete_emp_length_12_one_hot',\r\n",
        " 'discrete_emp_length_1_one_hot',\r\n",
        " 'discrete_emp_length_7_one_hot',\r\n",
        " 'discrete_grade_2_one_hot',\r\n",
        " 'discrete_home_ownership_1_one_hot',\r\n",
        " 'discrete_home_ownership_2_one_hot',\r\n",
        " 'discrete_home_ownership_3_one_hot',\r\n",
        " 'discrete_purpose_1_one_hot',\r\n",
        " 'discrete_purpose_3_one_hot',\r\n",
        " 'discrete_purpose_5_one_hot',\r\n",
        " 'discrete_sub_grade_18_one_hot',\r\n",
        " 'discrete_sub_grade_25_one_hot',\r\n",
        " 'discrete_sub_grade_3_one_hot',\r\n",
        " 'discrete_term_1_one_hot',\r\n",
        " 'discrete_term_2_one_hot']"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLpYkp6Eld96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4330640d-c601-4e94-da96-846a8a307927"
      },
      "source": [
        "train_copy = train.copy()\r\n",
        "test_copy = test.copy()\r\n",
        "print('原始数据',train_copy.shape, test_copy.shape)\r\n",
        "\r\n",
        "#连续特征处理\r\n",
        "for ix_i in range(0,len(continoue_cols)-1):\r\n",
        "    for ix_j in range(ix_i+1, len(continoue_cols)):\r\n",
        "        i = continoue_cols[ix_i]\r\n",
        "        j = continoue_cols[ix_j]\r\n",
        "        train_copy['new_'+i+'*'+j] = train_copy[i] * train_copy[j]\r\n",
        "        train_copy['new_'+i+'/'+j] = train_copy[i] / (train_copy[j]+1)\r\n",
        "        train_copy['new_'+i+'-'+j] = train_copy[i] - train_copy[j]\r\n",
        "        \r\n",
        "        test_copy['new_'+i+'*'+j] = test_copy[i] * test_copy[j]\r\n",
        "        test_copy['new_'+i+'/'+j] = test_copy[i] / (test_copy[j]+1)\r\n",
        "        test_copy['new_'+i+'-'+j] = test_copy[i] - test_copy[j]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "原始数据 (50000, 146) (50000, 146)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YylXSGIlkLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "446ba601-ca2d-4a26-9e16-0a93942383e7"
      },
      "source": [
        "#看一下离散取值\r\n",
        "for i in discrete_cols:\r\n",
        "    print(set(train_copy[i]))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "{0, 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv-U_IpBlmgj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db2977c-df9c-4fb7-afae-8e896603fe3e"
      },
      "source": [
        "#离散变量处理。为了方便直接做了label encoding\r\n",
        "label_dict = {'00':1,'01':2,'10':3,'11':4}\r\n",
        "for ix_i in range(0,len(discrete_cols)-1):\r\n",
        "    for ix_j in range(ix_i+1, len(discrete_cols)):\r\n",
        "        i = discrete_cols[ix_i]\r\n",
        "        j = discrete_cols[ix_j]\r\n",
        "        str_f_train = pd.Series([str(i)+str(j) for i,j in zip(train_copy[i], train_copy[j])])\r\n",
        "        train_copy['new_'+i+'*'+j] = str_f_train.map(label_dict)\r\n",
        "        \r\n",
        "        str_f_test = pd.Series([str(i)+str(j) for i,j in zip(test_copy[i], test_copy[j])])\r\n",
        "        test_copy['new_'+i+'*'+j] = str_f_test.map(label_dict)\r\n",
        "\r\n",
        "print('生成特征后',train_copy.shape, test_copy.shape)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "生成特征后 (50000, 881) (50000, 881)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsTj3tqeltey",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e3d066-59c8-49c3-d617-f30857d25afa"
      },
      "source": [
        "#生成特征后跑一下 看看结果\r\n",
        "folds = KFold(n_splits=5,shuffle=True, random_state=42)\r\n",
        "params = {'objective': 'binary',\r\n",
        "         'metric':'binary_logloss'\r\n",
        "         }\r\n",
        "\r\n",
        "loss_train_list = []\r\n",
        "loss_eval_list = []\r\n",
        "loss_test_list = []\r\n",
        "    \r\n",
        "for train_ix, eval_ix in folds.split(train_copy):\r\n",
        "    train_df = train_copy.loc[train_ix]\r\n",
        "    eval_df = train_copy.loc[eval_ix]\r\n",
        "    \r\n",
        "    clf = lgb.LGBMClassifier(boosting_type='gbdt', \r\n",
        "                  objective =\"binary\",\r\n",
        "                  metric= 'binary_logloss'\r\n",
        "                  ).fit(train_df.drop(columns=['loan_status']), train_df['loan_status'],\r\n",
        "                        eval_names=[\"train\",\"val\"],\r\n",
        "                        eval_set=[(train_df.drop(columns=['loan_status']), train_df['loan_status']),\r\n",
        "                                  (eval_df.drop(columns=['loan_status']), eval_df['loan_status'])],\r\n",
        "                        eval_metric='binary_logloss',\r\n",
        "                        verbose=20)\r\n",
        "    \r\n",
        "    ytrain = clf.predict_proba(train_df.drop(columns=['loan_status']))[:,1]\r\n",
        "    yeval = clf.predict_proba(eval_df.drop(columns=['loan_status']))[:,1]\r\n",
        "    ytest = clf.predict_proba(test_copy.drop(columns=['loan_status']))[:,1]\r\n",
        "    \r\n",
        "    \r\n",
        "    loss_train = metrics.log_loss(train_df['loan_status'],ytrain)\r\n",
        "    loss_eval = metrics.log_loss(eval_df['loan_status'],yeval)\r\n",
        "    loss_test = metrics.log_loss(test_copy['loan_status'],ytest)\r\n",
        "    print('train logloss',loss_train, 'eval logloss',loss_eval, 'test logloss',loss_test )\r\n",
        "    \r\n",
        "    loss_train_list.append(loss_train)\r\n",
        "    loss_eval_list.append(loss_eval)\r\n",
        "    loss_test_list.append(loss_test)\r\n",
        "\r\n",
        "    ytrainL = getLabel(ytrain)\r\n",
        "    yevalL = getLabel(yeval)\r\n",
        "    ytestL = getLabel(ytest)\r\n",
        "    print(\"train classification report\")\r\n",
        "    print(metrics.classification_report(train_df['loan_status'],ytrainL))\r\n",
        "    print(\"****************report1.************\")\r\n",
        "    print(\"val classification report\")\r\n",
        "    print(metrics.classification_report(eval_df['loan_status'],yevalL))\r\n",
        "    print(\"****************report2.************\")\r\n",
        "    print(\"target classification report\")\r\n",
        "    print(metrics.classification_report(test['loan_status'],ytestL))\r\n",
        "    print(\"****************report3.************\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[20]\ttrain's binary_logloss: 0.197769\tval's binary_logloss: 0.212984\n",
            "[40]\ttrain's binary_logloss: 0.169381\tval's binary_logloss: 0.199744\n",
            "[60]\ttrain's binary_logloss: 0.155281\tval's binary_logloss: 0.199561\n",
            "[80]\ttrain's binary_logloss: 0.144669\tval's binary_logloss: 0.20017\n",
            "[100]\ttrain's binary_logloss: 0.135981\tval's binary_logloss: 0.201093\n",
            "train logloss 0.13598108765305827 eval logloss 0.20109302846309723 test logloss 0.1998971445069125\n",
            "train classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86      8149\n",
            "           1       0.97      0.96      0.96     31851\n",
            "\n",
            "    accuracy                           0.94     40000\n",
            "   macro avg       0.91      0.91      0.91     40000\n",
            "weighted avg       0.94      0.94      0.94     40000\n",
            "\n",
            "****************report1.************\n",
            "val classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.82      0.80      2063\n",
            "           1       0.95      0.94      0.95      7937\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.87      0.88      0.88     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "****************report2.************\n",
            "target classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.79      9774\n",
            "           1       0.95      0.94      0.95     40226\n",
            "\n",
            "    accuracy                           0.92     50000\n",
            "   macro avg       0.86      0.87      0.87     50000\n",
            "weighted avg       0.92      0.92      0.92     50000\n",
            "\n",
            "****************report3.************\n",
            "[20]\ttrain's binary_logloss: 0.197882\tval's binary_logloss: 0.214299\n",
            "[40]\ttrain's binary_logloss: 0.169745\tval's binary_logloss: 0.199495\n",
            "[60]\ttrain's binary_logloss: 0.155549\tval's binary_logloss: 0.199104\n",
            "[80]\ttrain's binary_logloss: 0.145308\tval's binary_logloss: 0.19992\n",
            "[100]\ttrain's binary_logloss: 0.13666\tval's binary_logloss: 0.20024\n",
            "train logloss 0.13666013670911709 eval logloss 0.2002395578208826 test logloss 0.20065182889463754\n",
            "train classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86      8137\n",
            "           1       0.97      0.96      0.96     31863\n",
            "\n",
            "    accuracy                           0.94     40000\n",
            "   macro avg       0.91      0.92      0.91     40000\n",
            "weighted avg       0.94      0.94      0.94     40000\n",
            "\n",
            "****************report1.************\n",
            "val classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80      2075\n",
            "           1       0.95      0.95      0.95      7925\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.88      0.87      0.87     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "****************report2.************\n",
            "target classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.80      0.79      9774\n",
            "           1       0.95      0.95      0.95     40226\n",
            "\n",
            "    accuracy                           0.92     50000\n",
            "   macro avg       0.87      0.87      0.87     50000\n",
            "weighted avg       0.92      0.92      0.92     50000\n",
            "\n",
            "****************report3.************\n",
            "[20]\ttrain's binary_logloss: 0.197318\tval's binary_logloss: 0.21612\n",
            "[40]\ttrain's binary_logloss: 0.169215\tval's binary_logloss: 0.202728\n",
            "[60]\ttrain's binary_logloss: 0.155326\tval's binary_logloss: 0.202348\n",
            "[80]\ttrain's binary_logloss: 0.144071\tval's binary_logloss: 0.20337\n",
            "[100]\ttrain's binary_logloss: 0.135336\tval's binary_logloss: 0.204568\n",
            "train logloss 0.13533587369743955 eval logloss 0.20456792929643472 test logloss 0.19925537435312785\n",
            "train classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86      8179\n",
            "           1       0.97      0.96      0.96     31821\n",
            "\n",
            "    accuracy                           0.94     40000\n",
            "   macro avg       0.91      0.92      0.91     40000\n",
            "weighted avg       0.94      0.94      0.94     40000\n",
            "\n",
            "****************report1.************\n",
            "val classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.79      0.79      2033\n",
            "           1       0.95      0.95      0.95      7967\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "****************report2.************\n",
            "target classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.79      9774\n",
            "           1       0.95      0.94      0.95     40226\n",
            "\n",
            "    accuracy                           0.92     50000\n",
            "   macro avg       0.87      0.88      0.87     50000\n",
            "weighted avg       0.92      0.92      0.92     50000\n",
            "\n",
            "****************report3.************\n",
            "[20]\ttrain's binary_logloss: 0.199749\tval's binary_logloss: 0.208189\n",
            "[40]\ttrain's binary_logloss: 0.171504\tval's binary_logloss: 0.192855\n",
            "[60]\ttrain's binary_logloss: 0.157581\tval's binary_logloss: 0.192811\n",
            "[80]\ttrain's binary_logloss: 0.147127\tval's binary_logloss: 0.193837\n",
            "[100]\ttrain's binary_logloss: 0.138386\tval's binary_logloss: 0.194609\n",
            "train logloss 0.13838553683796131 eval logloss 0.19460927021334096 test logloss 0.19983309030793545\n",
            "train classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86      8172\n",
            "           1       0.97      0.96      0.96     31828\n",
            "\n",
            "    accuracy                           0.94     40000\n",
            "   macro avg       0.91      0.91      0.91     40000\n",
            "weighted avg       0.94      0.94      0.94     40000\n",
            "\n",
            "****************report1.************\n",
            "val classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.82      0.81      2040\n",
            "           1       0.95      0.95      0.95      7960\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "****************report2.************\n",
            "target classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.79      9774\n",
            "           1       0.95      0.94      0.95     40226\n",
            "\n",
            "    accuracy                           0.92     50000\n",
            "   macro avg       0.87      0.88      0.87     50000\n",
            "weighted avg       0.92      0.92      0.92     50000\n",
            "\n",
            "****************report3.************\n",
            "[20]\ttrain's binary_logloss: 0.198998\tval's binary_logloss: 0.210226\n",
            "[40]\ttrain's binary_logloss: 0.17047\tval's binary_logloss: 0.196848\n",
            "[60]\ttrain's binary_logloss: 0.156434\tval's binary_logloss: 0.196505\n",
            "[80]\ttrain's binary_logloss: 0.145916\tval's binary_logloss: 0.197192\n",
            "[100]\ttrain's binary_logloss: 0.137174\tval's binary_logloss: 0.197882\n",
            "train logloss 0.1371740151088775 eval logloss 0.19788240104787563 test logloss 0.2003739010640542\n",
            "train classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86      8211\n",
            "           1       0.97      0.96      0.96     31789\n",
            "\n",
            "    accuracy                           0.94     40000\n",
            "   macro avg       0.91      0.92      0.91     40000\n",
            "weighted avg       0.94      0.94      0.94     40000\n",
            "\n",
            "****************report1.************\n",
            "val classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.82      0.81      2001\n",
            "           1       0.95      0.95      0.95      7999\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.87      0.88      0.88     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "****************report2.************\n",
            "target classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.79      9774\n",
            "           1       0.95      0.94      0.95     40226\n",
            "\n",
            "    accuracy                           0.92     50000\n",
            "   macro avg       0.86      0.87      0.87     50000\n",
            "weighted avg       0.92      0.92      0.92     50000\n",
            "\n",
            "****************report3.************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdJhF0RRmdfT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ca61bb6-16e1-4512-c5a2-5b53bf51695b"
      },
      "source": [
        "print('avg train loss', np.mean(loss_train_list),'avg eval loss', \r\n",
        "      np.mean(loss_eval_list),'avg test loss', np.mean(loss_test_list))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avg train loss 0.13670733000129073 avg eval loss 0.19967843736832624 avg test loss 0.20000226782533354\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgdXJx5smjsd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c02a368d-2d15-4e23-c741-7e455c2cbad9"
      },
      "source": [
        "#生成特征，调参后的结果，并给出此时的特征重要性，验证下生成的特征是不是比之前的有用\r\n",
        "folds = KFold(n_splits=5,shuffle=True, random_state=42)\r\n",
        "loss_train_list = []\r\n",
        "loss_eval_list = []\r\n",
        "loss_test_list = []\r\n",
        "key_cols = []\r\n",
        "    \r\n",
        "for train_ix, eval_ix in folds.split(train_copy):\r\n",
        "    train_df = train_copy.loc[train_ix]\r\n",
        "    eval_df = train_copy.loc[eval_ix]\r\n",
        "    \r\n",
        "    clf = lgb.LGBMClassifier(boosting_type='gbdt', \r\n",
        "            objective =\"binary\",\r\n",
        "            metric= 'binary_logloss',\r\n",
        "            colsample_bytree =0.7, \r\n",
        "            learning_rate = 0.02, \r\n",
        "            n_estimators = 300,\r\n",
        "            num_leaves = 20, \r\n",
        "            subsample = 0.65,\r\n",
        "            importance_type ='gain'\r\n",
        "            ).fit(train_df.drop(columns=['loan_status']), train_df['loan_status'],\r\n",
        "                  eval_names=[\"train\",\"val\"],\r\n",
        "                  eval_set=[(train_df.drop(columns=['loan_status']), train_df['loan_status']),\r\n",
        "                            (eval_df.drop(columns=['loan_status']), eval_df['loan_status'])],\r\n",
        "                  eval_metric='binary_logloss',\r\n",
        "                  verbose=20)\r\n",
        "    \r\n",
        "    ytrain = clf.predict_proba(train_df.drop(columns=['loan_status']))[:,1]\r\n",
        "    yeval = clf.predict_proba(eval_df.drop(columns=['loan_status']))[:,1]\r\n",
        "    ytest = clf.predict_proba(test_copy.drop(columns=['loan_status']))[:,1]\r\n",
        "    \r\n",
        "    \r\n",
        "    loss_train = metrics.log_loss(train_df['loan_status'],ytrain)\r\n",
        "    loss_eval = metrics.log_loss(eval_df['loan_status'],yeval)\r\n",
        "    loss_test = metrics.log_loss(test['loan_status'],ytest)\r\n",
        "    print('train logloss',loss_train, 'eval logloss',loss_eval, 'test logloss',loss_test )\r\n",
        "    \r\n",
        "    loss_train_list.append(loss_train)\r\n",
        "    loss_eval_list.append(loss_eval)\r\n",
        "    loss_test_list.append(loss_test)\r\n",
        "\r\n",
        "    ytrainL = getLabel(ytrain)\r\n",
        "    yevalL = getLabel(yeval)\r\n",
        "    ytestL = getLabel(ytest)\r\n",
        "    print(\"train classification report\")\r\n",
        "    print(metrics.classification_report(train_df['loan_status'],ytrainL))\r\n",
        "    print(\"***********classification report1.********\")\r\n",
        "    print(\"val classification report\")\r\n",
        "    print(metrics.classification_report(eval_df['loan_status'],yevalL))\r\n",
        "    print(\"***********classification report2.********\")\r\n",
        "    print(\"target classification report\")\r\n",
        "    print(metrics.classification_report(test['loan_status'],ytestL))\r\n",
        "    print(\"***********classification report3.********\")\r\n",
        "    \r\n",
        "    feature_importance = pd.DataFrame({'feature_name': clf.booster_.feature_name(),\r\n",
        "                                       'importance': clf.feature_importances_})\r\n",
        "    feature_importance.sort_index(ascending=False, inplace=True)\r\n",
        "    print(feature_importance[:30])\r\n",
        "    for c in feature_importance[:30]['feature_name']:\r\n",
        "        key_cols.append(c)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[20]\ttrain's binary_logloss: 0.349334\tval's binary_logloss: 0.352442\n",
            "[40]\ttrain's binary_logloss: 0.279204\tval's binary_logloss: 0.283373\n",
            "[60]\ttrain's binary_logloss: 0.240793\tval's binary_logloss: 0.246453\n",
            "[80]\ttrain's binary_logloss: 0.218335\tval's binary_logloss: 0.2256\n",
            "[100]\ttrain's binary_logloss: 0.204663\tval's binary_logloss: 0.213744\n",
            "[120]\ttrain's binary_logloss: 0.19599\tval's binary_logloss: 0.206881\n",
            "[140]\ttrain's binary_logloss: 0.190136\tval's binary_logloss: 0.202907\n",
            "[160]\ttrain's binary_logloss: 0.185921\tval's binary_logloss: 0.200687\n",
            "[180]\ttrain's binary_logloss: 0.182574\tval's binary_logloss: 0.199592\n",
            "[200]\ttrain's binary_logloss: 0.179775\tval's binary_logloss: 0.1989\n",
            "[220]\ttrain's binary_logloss: 0.177254\tval's binary_logloss: 0.198387\n",
            "[240]\ttrain's binary_logloss: 0.174889\tval's binary_logloss: 0.198275\n",
            "[260]\ttrain's binary_logloss: 0.172839\tval's binary_logloss: 0.198185\n",
            "[280]\ttrain's binary_logloss: 0.170959\tval's binary_logloss: 0.198096\n",
            "[300]\ttrain's binary_logloss: 0.169194\tval's binary_logloss: 0.198045\n",
            "train logloss 0.16919407595471758 eval logloss 0.19804505366345942 test logloss 0.19692564562556633\n",
            "train classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83      8149\n",
            "           1       0.96      0.95      0.96     31851\n",
            "\n",
            "    accuracy                           0.93     40000\n",
            "   macro avg       0.89      0.89      0.89     40000\n",
            "weighted avg       0.93      0.93      0.93     40000\n",
            "\n",
            "***********classification report1.********\n",
            "val classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.83      0.81      2063\n",
            "           1       0.96      0.94      0.95      7937\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.87      0.89      0.88     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "***********classification report2.********\n",
            "target classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.79      9774\n",
            "           1       0.95      0.94      0.95     40226\n",
            "\n",
            "    accuracy                           0.92     50000\n",
            "   macro avg       0.87      0.88      0.87     50000\n",
            "weighted avg       0.92      0.92      0.92     50000\n",
            "\n",
            "***********classification report3.********\n",
            "                                          feature_name  importance\n",
            "879  new_discrete_term_1_one_hot*discrete_term_2_on...       0.000\n",
            "878  new_discrete_sub_grade_3_one_hot*discrete_term...      28.368\n",
            "877  new_discrete_sub_grade_3_one_hot*discrete_term...      20.557\n",
            "876  new_discrete_sub_grade_25_one_hot*discrete_ter...       0.000\n",
            "875  new_discrete_sub_grade_25_one_hot*discrete_ter...      33.587\n",
            "874  new_discrete_sub_grade_25_one_hot*discrete_sub...       0.000\n",
            "873  new_discrete_sub_grade_18_one_hot*discrete_ter...       0.000\n",
            "872  new_discrete_sub_grade_18_one_hot*discrete_ter...     728.703\n",
            "871  new_discrete_sub_grade_18_one_hot*discrete_sub...       0.000\n",
            "870  new_discrete_sub_grade_18_one_hot*discrete_sub...       0.000\n",
            "869  new_discrete_purpose_5_one_hot*discrete_term_2...     157.450\n",
            "868  new_discrete_purpose_5_one_hot*discrete_term_1...      44.970\n",
            "867  new_discrete_purpose_5_one_hot*discrete_sub_gr...       8.717\n",
            "866  new_discrete_purpose_5_one_hot*discrete_sub_gr...      50.134\n",
            "865  new_discrete_purpose_5_one_hot*discrete_sub_gr...       0.000\n",
            "864  new_discrete_purpose_3_one_hot*discrete_term_2...     275.335\n",
            "863  new_discrete_purpose_3_one_hot*discrete_term_1...     560.273\n",
            "862  new_discrete_purpose_3_one_hot*discrete_sub_gr...       0.000\n",
            "861  new_discrete_purpose_3_one_hot*discrete_sub_gr...      18.958\n",
            "860  new_discrete_purpose_3_one_hot*discrete_sub_gr...      50.898\n",
            "859  new_discrete_purpose_3_one_hot*discrete_purpos...       9.641\n",
            "858  new_discrete_purpose_1_one_hot*discrete_term_2...       0.000\n",
            "857  new_discrete_purpose_1_one_hot*discrete_term_1...      42.699\n",
            "856  new_discrete_purpose_1_one_hot*discrete_sub_gr...      78.000\n",
            "855  new_discrete_purpose_1_one_hot*discrete_sub_gr...      10.740\n",
            "854  new_discrete_purpose_1_one_hot*discrete_sub_gr...      20.322\n",
            "853  new_discrete_purpose_1_one_hot*discrete_purpos...       7.734\n",
            "852  new_discrete_purpose_1_one_hot*discrete_purpos...       0.000\n",
            "851  new_discrete_home_ownership_3_one_hot*discrete...     133.745\n",
            "850  new_discrete_home_ownership_3_one_hot*discrete...      10.826\n",
            "[20]\ttrain's binary_logloss: 0.348956\tval's binary_logloss: 0.355489\n",
            "[40]\ttrain's binary_logloss: 0.278844\tval's binary_logloss: 0.286251\n",
            "[60]\ttrain's binary_logloss: 0.24058\tval's binary_logloss: 0.248861\n",
            "[80]\ttrain's binary_logloss: 0.218201\tval's binary_logloss: 0.227333\n",
            "[100]\ttrain's binary_logloss: 0.204564\tval's binary_logloss: 0.214869\n",
            "[120]\ttrain's binary_logloss: 0.19589\tval's binary_logloss: 0.207554\n",
            "[140]\ttrain's binary_logloss: 0.190047\tval's binary_logloss: 0.203123\n",
            "[160]\ttrain's binary_logloss: 0.185872\tval's binary_logloss: 0.200531\n",
            "[180]\ttrain's binary_logloss: 0.182624\tval's binary_logloss: 0.199008\n",
            "[200]\ttrain's binary_logloss: 0.179868\tval's binary_logloss: 0.198302\n",
            "[220]\ttrain's binary_logloss: 0.177316\tval's binary_logloss: 0.197889\n",
            "[240]\ttrain's binary_logloss: 0.175049\tval's binary_logloss: 0.197522\n",
            "[260]\ttrain's binary_logloss: 0.173003\tval's binary_logloss: 0.197353\n",
            "[280]\ttrain's binary_logloss: 0.171155\tval's binary_logloss: 0.197164\n",
            "[300]\ttrain's binary_logloss: 0.169411\tval's binary_logloss: 0.197108\n",
            "train logloss 0.16941112521310348 eval logloss 0.19710793374997776 test logloss 0.19741023727482457\n",
            "train classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83      8137\n",
            "           1       0.96      0.95      0.96     31863\n",
            "\n",
            "    accuracy                           0.93     40000\n",
            "   macro avg       0.89      0.90      0.89     40000\n",
            "weighted avg       0.93      0.93      0.93     40000\n",
            "\n",
            "***********classification report1.********\n",
            "val classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.80      0.81      2075\n",
            "           1       0.95      0.95      0.95      7925\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "***********classification report2.********\n",
            "target classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.79      9774\n",
            "           1       0.95      0.95      0.95     40226\n",
            "\n",
            "    accuracy                           0.92     50000\n",
            "   macro avg       0.87      0.88      0.87     50000\n",
            "weighted avg       0.92      0.92      0.92     50000\n",
            "\n",
            "***********classification report3.********\n",
            "                                          feature_name  importance\n",
            "879  new_discrete_term_1_one_hot*discrete_term_2_on...       0.000\n",
            "878  new_discrete_sub_grade_3_one_hot*discrete_term...      89.495\n",
            "877  new_discrete_sub_grade_3_one_hot*discrete_term...       0.000\n",
            "876  new_discrete_sub_grade_25_one_hot*discrete_ter...       0.000\n",
            "875  new_discrete_sub_grade_25_one_hot*discrete_ter...     306.462\n",
            "874  new_discrete_sub_grade_25_one_hot*discrete_sub...      11.132\n",
            "873  new_discrete_sub_grade_18_one_hot*discrete_ter...      43.851\n",
            "872  new_discrete_sub_grade_18_one_hot*discrete_ter...     444.839\n",
            "871  new_discrete_sub_grade_18_one_hot*discrete_sub...       0.000\n",
            "870  new_discrete_sub_grade_18_one_hot*discrete_sub...      11.321\n",
            "869  new_discrete_purpose_5_one_hot*discrete_term_2...       7.862\n",
            "868  new_discrete_purpose_5_one_hot*discrete_term_1...       0.000\n",
            "867  new_discrete_purpose_5_one_hot*discrete_sub_gr...       0.000\n",
            "866  new_discrete_purpose_5_one_hot*discrete_sub_gr...       0.000\n",
            "865  new_discrete_purpose_5_one_hot*discrete_sub_gr...       0.000\n",
            "864  new_discrete_purpose_3_one_hot*discrete_term_2...     326.093\n",
            "863  new_discrete_purpose_3_one_hot*discrete_term_1...    1159.564\n",
            "862  new_discrete_purpose_3_one_hot*discrete_sub_gr...       0.000\n",
            "861  new_discrete_purpose_3_one_hot*discrete_sub_gr...      20.704\n",
            "860  new_discrete_purpose_3_one_hot*discrete_sub_gr...      12.568\n",
            "859  new_discrete_purpose_3_one_hot*discrete_purpos...       0.000\n",
            "858  new_discrete_purpose_1_one_hot*discrete_term_2...       0.000\n",
            "857  new_discrete_purpose_1_one_hot*discrete_term_1...      15.377\n",
            "856  new_discrete_purpose_1_one_hot*discrete_sub_gr...       0.000\n",
            "855  new_discrete_purpose_1_one_hot*discrete_sub_gr...      23.176\n",
            "854  new_discrete_purpose_1_one_hot*discrete_sub_gr...       0.000\n",
            "853  new_discrete_purpose_1_one_hot*discrete_purpos...      16.246\n",
            "852  new_discrete_purpose_1_one_hot*discrete_purpos...       0.000\n",
            "851  new_discrete_home_ownership_3_one_hot*discrete...     145.671\n",
            "850  new_discrete_home_ownership_3_one_hot*discrete...       0.000\n",
            "[20]\ttrain's binary_logloss: 0.349509\tval's binary_logloss: 0.353045\n",
            "[40]\ttrain's binary_logloss: 0.278917\tval's binary_logloss: 0.285577\n",
            "[60]\ttrain's binary_logloss: 0.240389\tval's binary_logloss: 0.249407\n",
            "[80]\ttrain's binary_logloss: 0.217901\tval's binary_logloss: 0.229077\n",
            "[100]\ttrain's binary_logloss: 0.204242\tval's binary_logloss: 0.217341\n",
            "[120]\ttrain's binary_logloss: 0.195607\tval's binary_logloss: 0.210605\n",
            "[140]\ttrain's binary_logloss: 0.189824\tval's binary_logloss: 0.206552\n",
            "[160]\ttrain's binary_logloss: 0.185688\tval's binary_logloss: 0.204259\n",
            "[180]\ttrain's binary_logloss: 0.182457\tval's binary_logloss: 0.202963\n",
            "[200]\ttrain's binary_logloss: 0.179729\tval's binary_logloss: 0.202127\n",
            "[220]\ttrain's binary_logloss: 0.177314\tval's binary_logloss: 0.201612\n",
            "[240]\ttrain's binary_logloss: 0.17518\tval's binary_logloss: 0.201293\n",
            "[260]\ttrain's binary_logloss: 0.173099\tval's binary_logloss: 0.201156\n",
            "[280]\ttrain's binary_logloss: 0.171231\tval's binary_logloss: 0.201077\n",
            "[300]\ttrain's binary_logloss: 0.169577\tval's binary_logloss: 0.201003\n",
            "train logloss 0.16957684080993157 eval logloss 0.20100276975013218 test logloss 0.19688978183998668\n",
            "train classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83      8179\n",
            "           1       0.96      0.95      0.96     31821\n",
            "\n",
            "    accuracy                           0.93     40000\n",
            "   macro avg       0.89      0.90      0.89     40000\n",
            "weighted avg       0.93      0.93      0.93     40000\n",
            "\n",
            "***********classification report1.********\n",
            "val classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.81      0.80      2033\n",
            "           1       0.95      0.95      0.95      7967\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "***********classification report2.********\n",
            "target classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.79      9774\n",
            "           1       0.95      0.94      0.95     40226\n",
            "\n",
            "    accuracy                           0.92     50000\n",
            "   macro avg       0.87      0.88      0.87     50000\n",
            "weighted avg       0.92      0.92      0.92     50000\n",
            "\n",
            "***********classification report3.********\n",
            "                                          feature_name  importance\n",
            "879  new_discrete_term_1_one_hot*discrete_term_2_on...       0.000\n",
            "878  new_discrete_sub_grade_3_one_hot*discrete_term...     160.307\n",
            "877  new_discrete_sub_grade_3_one_hot*discrete_term...       0.000\n",
            "876  new_discrete_sub_grade_25_one_hot*discrete_ter...       0.000\n",
            "875  new_discrete_sub_grade_25_one_hot*discrete_ter...       0.000\n",
            "874  new_discrete_sub_grade_25_one_hot*discrete_sub...      25.354\n",
            "873  new_discrete_sub_grade_18_one_hot*discrete_ter...      15.395\n",
            "872  new_discrete_sub_grade_18_one_hot*discrete_ter...     672.186\n",
            "871  new_discrete_sub_grade_18_one_hot*discrete_sub...       0.000\n",
            "870  new_discrete_sub_grade_18_one_hot*discrete_sub...       0.000\n",
            "869  new_discrete_purpose_5_one_hot*discrete_term_2...      44.718\n",
            "868  new_discrete_purpose_5_one_hot*discrete_term_1...       0.000\n",
            "867  new_discrete_purpose_5_one_hot*discrete_sub_gr...       0.000\n",
            "866  new_discrete_purpose_5_one_hot*discrete_sub_gr...      11.312\n",
            "865  new_discrete_purpose_5_one_hot*discrete_sub_gr...      25.113\n",
            "864  new_discrete_purpose_3_one_hot*discrete_term_2...     305.678\n",
            "863  new_discrete_purpose_3_one_hot*discrete_term_1...     179.355\n",
            "862  new_discrete_purpose_3_one_hot*discrete_sub_gr...      25.507\n",
            "861  new_discrete_purpose_3_one_hot*discrete_sub_gr...       0.000\n",
            "860  new_discrete_purpose_3_one_hot*discrete_sub_gr...       0.000\n",
            "859  new_discrete_purpose_3_one_hot*discrete_purpos...      29.459\n",
            "858  new_discrete_purpose_1_one_hot*discrete_term_2...       0.000\n",
            "857  new_discrete_purpose_1_one_hot*discrete_term_1...      41.782\n",
            "856  new_discrete_purpose_1_one_hot*discrete_sub_gr...      19.035\n",
            "855  new_discrete_purpose_1_one_hot*discrete_sub_gr...       0.000\n",
            "854  new_discrete_purpose_1_one_hot*discrete_sub_gr...      11.850\n",
            "853  new_discrete_purpose_1_one_hot*discrete_purpos...      10.639\n",
            "852  new_discrete_purpose_1_one_hot*discrete_purpos...      38.579\n",
            "851  new_discrete_home_ownership_3_one_hot*discrete...      48.288\n",
            "850  new_discrete_home_ownership_3_one_hot*discrete...       0.000\n",
            "[20]\ttrain's binary_logloss: 0.350646\tval's binary_logloss: 0.350176\n",
            "[40]\ttrain's binary_logloss: 0.280517\tval's binary_logloss: 0.280547\n",
            "[60]\ttrain's binary_logloss: 0.242237\tval's binary_logloss: 0.243117\n",
            "[80]\ttrain's binary_logloss: 0.219892\tval's binary_logloss: 0.22178\n",
            "[100]\ttrain's binary_logloss: 0.206402\tval's binary_logloss: 0.209339\n",
            "[120]\ttrain's binary_logloss: 0.197851\tval's binary_logloss: 0.202034\n",
            "[140]\ttrain's binary_logloss: 0.192028\tval's binary_logloss: 0.197506\n",
            "[160]\ttrain's binary_logloss: 0.187863\tval's binary_logloss: 0.194945\n",
            "[180]\ttrain's binary_logloss: 0.184581\tval's binary_logloss: 0.193504\n",
            "[200]\ttrain's binary_logloss: 0.181834\tval's binary_logloss: 0.192575\n",
            "[220]\ttrain's binary_logloss: 0.179358\tval's binary_logloss: 0.192077\n",
            "[240]\ttrain's binary_logloss: 0.177125\tval's binary_logloss: 0.191775\n",
            "[260]\ttrain's binary_logloss: 0.175097\tval's binary_logloss: 0.191596\n",
            "[280]\ttrain's binary_logloss: 0.173121\tval's binary_logloss: 0.19158\n",
            "[300]\ttrain's binary_logloss: 0.171324\tval's binary_logloss: 0.191536\n",
            "train logloss 0.1713236073745249 eval logloss 0.19153639160434982 test logloss 0.19715888060176487\n",
            "train classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.83      0.83      8172\n",
            "           1       0.96      0.95      0.95     31828\n",
            "\n",
            "    accuracy                           0.93     40000\n",
            "   macro avg       0.89      0.89      0.89     40000\n",
            "weighted avg       0.93      0.93      0.93     40000\n",
            "\n",
            "***********classification report1.********\n",
            "val classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.82      0.81      2040\n",
            "           1       0.95      0.95      0.95      7960\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "***********classification report2.********\n",
            "target classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.80      9774\n",
            "           1       0.95      0.94      0.95     40226\n",
            "\n",
            "    accuracy                           0.92     50000\n",
            "   macro avg       0.87      0.88      0.87     50000\n",
            "weighted avg       0.92      0.92      0.92     50000\n",
            "\n",
            "***********classification report3.********\n",
            "                                          feature_name  importance\n",
            "879  new_discrete_term_1_one_hot*discrete_term_2_on...       0.000\n",
            "878  new_discrete_sub_grade_3_one_hot*discrete_term...     210.611\n",
            "877  new_discrete_sub_grade_3_one_hot*discrete_term...       0.000\n",
            "876  new_discrete_sub_grade_25_one_hot*discrete_ter...      18.154\n",
            "875  new_discrete_sub_grade_25_one_hot*discrete_ter...      59.570\n",
            "874  new_discrete_sub_grade_25_one_hot*discrete_sub...       0.000\n",
            "873  new_discrete_sub_grade_18_one_hot*discrete_ter...       0.000\n",
            "872  new_discrete_sub_grade_18_one_hot*discrete_ter...     244.706\n",
            "871  new_discrete_sub_grade_18_one_hot*discrete_sub...       0.000\n",
            "870  new_discrete_sub_grade_18_one_hot*discrete_sub...      11.240\n",
            "869  new_discrete_purpose_5_one_hot*discrete_term_2...      74.412\n",
            "868  new_discrete_purpose_5_one_hot*discrete_term_1...      19.295\n",
            "867  new_discrete_purpose_5_one_hot*discrete_sub_gr...       0.000\n",
            "866  new_discrete_purpose_5_one_hot*discrete_sub_gr...       7.200\n",
            "865  new_discrete_purpose_5_one_hot*discrete_sub_gr...      29.458\n",
            "864  new_discrete_purpose_3_one_hot*discrete_term_2...      27.398\n",
            "863  new_discrete_purpose_3_one_hot*discrete_term_1...     343.799\n",
            "862  new_discrete_purpose_3_one_hot*discrete_sub_gr...       0.000\n",
            "861  new_discrete_purpose_3_one_hot*discrete_sub_gr...      39.354\n",
            "860  new_discrete_purpose_3_one_hot*discrete_sub_gr...     147.454\n",
            "859  new_discrete_purpose_3_one_hot*discrete_purpos...       0.000\n",
            "858  new_discrete_purpose_1_one_hot*discrete_term_2...       0.000\n",
            "857  new_discrete_purpose_1_one_hot*discrete_term_1...      12.045\n",
            "856  new_discrete_purpose_1_one_hot*discrete_sub_gr...       0.000\n",
            "855  new_discrete_purpose_1_one_hot*discrete_sub_gr...       0.000\n",
            "854  new_discrete_purpose_1_one_hot*discrete_sub_gr...      43.606\n",
            "853  new_discrete_purpose_1_one_hot*discrete_purpos...      29.449\n",
            "852  new_discrete_purpose_1_one_hot*discrete_purpos...       9.274\n",
            "851  new_discrete_home_ownership_3_one_hot*discrete...     106.446\n",
            "850  new_discrete_home_ownership_3_one_hot*discrete...       0.000\n",
            "[20]\ttrain's binary_logloss: 0.351115\tval's binary_logloss: 0.347911\n",
            "[40]\ttrain's binary_logloss: 0.280657\tval's binary_logloss: 0.28013\n",
            "[60]\ttrain's binary_logloss: 0.242141\tval's binary_logloss: 0.243631\n",
            "[80]\ttrain's binary_logloss: 0.219629\tval's binary_logloss: 0.222899\n",
            "[100]\ttrain's binary_logloss: 0.205947\tval's binary_logloss: 0.210958\n",
            "[120]\ttrain's binary_logloss: 0.197223\tval's binary_logloss: 0.204197\n",
            "[140]\ttrain's binary_logloss: 0.191391\tval's binary_logloss: 0.200207\n",
            "[160]\ttrain's binary_logloss: 0.18713\tval's binary_logloss: 0.197765\n",
            "[180]\ttrain's binary_logloss: 0.183825\tval's binary_logloss: 0.1964\n",
            "[200]\ttrain's binary_logloss: 0.181024\tval's binary_logloss: 0.195662\n",
            "[220]\ttrain's binary_logloss: 0.178635\tval's binary_logloss: 0.195122\n",
            "[240]\ttrain's binary_logloss: 0.176284\tval's binary_logloss: 0.194799\n",
            "[260]\ttrain's binary_logloss: 0.174158\tval's binary_logloss: 0.194599\n",
            "[280]\ttrain's binary_logloss: 0.172234\tval's binary_logloss: 0.194496\n",
            "[300]\ttrain's binary_logloss: 0.170447\tval's binary_logloss: 0.194464\n",
            "train logloss 0.170447078194194 eval logloss 0.19446355590304848 test logloss 0.19742950864211584\n",
            "train classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.83      0.83      8211\n",
            "           1       0.96      0.95      0.96     31789\n",
            "\n",
            "    accuracy                           0.93     40000\n",
            "   macro avg       0.89      0.89      0.89     40000\n",
            "weighted avg       0.93      0.93      0.93     40000\n",
            "\n",
            "***********classification report1.********\n",
            "val classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.82      0.81      2001\n",
            "           1       0.95      0.95      0.95      7999\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "***********classification report2.********\n",
            "target classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.81      0.79      9774\n",
            "           1       0.95      0.94      0.95     40226\n",
            "\n",
            "    accuracy                           0.92     50000\n",
            "   macro avg       0.87      0.88      0.87     50000\n",
            "weighted avg       0.92      0.92      0.92     50000\n",
            "\n",
            "***********classification report3.********\n",
            "                                          feature_name  importance\n",
            "879  new_discrete_term_1_one_hot*discrete_term_2_on...     217.372\n",
            "878  new_discrete_sub_grade_3_one_hot*discrete_term...      81.481\n",
            "877  new_discrete_sub_grade_3_one_hot*discrete_term...       0.000\n",
            "876  new_discrete_sub_grade_25_one_hot*discrete_ter...     113.539\n",
            "875  new_discrete_sub_grade_25_one_hot*discrete_ter...       0.000\n",
            "874  new_discrete_sub_grade_25_one_hot*discrete_sub...       9.944\n",
            "873  new_discrete_sub_grade_18_one_hot*discrete_ter...       0.000\n",
            "872  new_discrete_sub_grade_18_one_hot*discrete_ter...       0.000\n",
            "871  new_discrete_sub_grade_18_one_hot*discrete_sub...       0.000\n",
            "870  new_discrete_sub_grade_18_one_hot*discrete_sub...       0.000\n",
            "869  new_discrete_purpose_5_one_hot*discrete_term_2...      22.144\n",
            "868  new_discrete_purpose_5_one_hot*discrete_term_1...      11.985\n",
            "867  new_discrete_purpose_5_one_hot*discrete_sub_gr...       0.000\n",
            "866  new_discrete_purpose_5_one_hot*discrete_sub_gr...       0.000\n",
            "865  new_discrete_purpose_5_one_hot*discrete_sub_gr...       0.000\n",
            "864  new_discrete_purpose_3_one_hot*discrete_term_2...      36.059\n",
            "863  new_discrete_purpose_3_one_hot*discrete_term_1...     987.524\n",
            "862  new_discrete_purpose_3_one_hot*discrete_sub_gr...      10.968\n",
            "861  new_discrete_purpose_3_one_hot*discrete_sub_gr...       0.000\n",
            "860  new_discrete_purpose_3_one_hot*discrete_sub_gr...       0.000\n",
            "859  new_discrete_purpose_3_one_hot*discrete_purpos...       0.000\n",
            "858  new_discrete_purpose_1_one_hot*discrete_term_2...      10.918\n",
            "857  new_discrete_purpose_1_one_hot*discrete_term_1...       0.000\n",
            "856  new_discrete_purpose_1_one_hot*discrete_sub_gr...      24.352\n",
            "855  new_discrete_purpose_1_one_hot*discrete_sub_gr...       0.000\n",
            "854  new_discrete_purpose_1_one_hot*discrete_sub_gr...      45.407\n",
            "853  new_discrete_purpose_1_one_hot*discrete_purpos...      80.443\n",
            "852  new_discrete_purpose_1_one_hot*discrete_purpos...       0.000\n",
            "851  new_discrete_home_ownership_3_one_hot*discrete...      17.567\n",
            "850  new_discrete_home_ownership_3_one_hot*discrete...       0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B23x9OKhoMUF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8b67087-cca5-4521-efd5-51d2b68c1e00"
      },
      "source": [
        "print('avg train loss', np.mean(loss_train_list),'avg eval loss', \r\n",
        "      np.mean(loss_eval_list),'avg test loss', np.mean(loss_test_list))\r\n",
        "\r\n",
        "\r\n",
        "newfeature_train_avgloss = np.mean(loss_train_list)\r\n",
        "newfeature_eval_avgloss = np.mean(loss_eval_list)\r\n",
        "newfeature_test_avgloss = np.mean(loss_test_list)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avg train loss 0.16999054550929432 avg eval loss 0.19643114093419353 avg test loss 0.19716281079685166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C99BZvMoVoz"
      },
      "source": [
        "# **结果对比**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV3_HjqPoZJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02a556dd-9da8-428e-9a7d-2e30cf95dd62"
      },
      "source": [
        "#loss对比\r\n",
        "\r\n",
        "print('train loss 差异：',np.linalg.norm(baseline_train_avgloss - newfeature_train_avgloss ))\r\n",
        "print('eval loss 差异：',np.linalg.norm(baseline_eval_avgloss - newfeature_eval_avgloss ))\r\n",
        "print('test loss 差异：',np.linalg.norm(baseline_test_avgloss - newfeature_test_avgloss ))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train loss 差异： 0.0010549355949296402\n",
            "eval loss 差异： 0.0007052997911332071\n",
            "test loss 差异： 0.000540310908670405\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}